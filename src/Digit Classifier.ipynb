{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 120, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 118, 318, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 59, 159, 16)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 57, 157, 32)  4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 28, 78, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 26, 76, 32)   9248        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 63232)        0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2023456     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 11)           363         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           363         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 11)           363         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 11)           363         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,039,244\n",
      "Trainable params: 2,039,244\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Dense, Flatten, Input\n",
    "\n",
    "\n",
    "visible = Input(shape=(120, 320, 3))\n",
    "conv1 = Conv2D(16, (3,3), activation='relu')(visible)\n",
    "pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "conv2 = Conv2D(32, (3,3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "conv3 = Conv2D(32, (3,3), activation='relu')(pool2)\n",
    "flat = Flatten()(conv3)\n",
    "hidden = Dense(32, activation='relu')(flat)\n",
    "\n",
    "output1 = Dense(11, activation = 'softmax')(hidden)\n",
    "output2 = Dense(11, activation = 'softmax')(hidden)\n",
    "output3 = Dense(11, activation = 'softmax')(hidden)\n",
    "output4 = Dense(11, activation = 'softmax')(hidden)\n",
    "\n",
    "model = Model(inputs = visible, outputs = [output1, output2, output3, output4])\n",
    "\n",
    "model.compile(optimizer='adam', loss=['categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy','categorical_crossentropy'], metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img_paths = []\n",
    "validation_img_paths = []\n",
    "\n",
    "\n",
    "for i in range(4500, 5000):\n",
    "    training_img_paths += ['digits data/boards/training/board_'+str(i)+'.jpg']\n",
    "    \n",
    "for i in range(500):\n",
    "    validation_img_paths += ['digits data/boards/validation/board_'+str(i)+'.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "def get_input(path):\n",
    "    img = cv2.imread(path)\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(path):\n",
    "    output1 = np.zeros(11)\n",
    "    output2 = np.zeros(11)\n",
    "    output3 = np.zeros(11)\n",
    "    output4 = np.zeros(11)\n",
    "    \n",
    "    img_id = path.split('_')[-1].split('.')[0]\n",
    "    label = np.load('digits data/labels/label_'+img_id+'.npy')\n",
    "    \n",
    "    output1[label[0]] = 1\n",
    "    output2[label[1]] = 1\n",
    "    output3[label[2]] = 1\n",
    "    output4[label[3]] = 1\n",
    "    \n",
    "    return output1, output2, output3, output4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(files, batch_size):\n",
    "    \n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_paths = np.random.choice(a = files, \n",
    "                                         size = batch_size)\n",
    "        batch_input = []\n",
    "        batch_output1 = [] \n",
    "        batch_output2 = []\n",
    "        batch_output3 = []\n",
    "        batch_output4 = []\n",
    "          \n",
    "        # Read in each input, perform preprocessing and get labels\n",
    "        for input_path in batch_paths:\n",
    "            input = get_input(input_path)\n",
    "            batch_output = get_output(input_path)\n",
    "\n",
    "            #input = preprocess_input(image=input) \n",
    "            batch_input += [ input ]\n",
    "            batch_output1 += [ batch_output[0] ]\n",
    "            batch_output2 += [ batch_output[1] ]\n",
    "            batch_output3 += [ batch_output[2] ]\n",
    "            batch_output4 += [ batch_output[3] ]\n",
    "            \n",
    "        # Return a tuple of (input,output) to feed the network\n",
    "        batch_x = np.array( batch_input )\n",
    "        batch_y1 = np.array( batch_output1 )\n",
    "        batch_y2 = np.array( batch_output2 )\n",
    "        batch_y3 = np.array( batch_output3 )\n",
    "        batch_y4 = np.array( batch_output4 )\n",
    "        \n",
    "        yield( batch_x, [batch_y1, batch_y2, batch_y3, batch_y4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "training_gen = image_generator(training_img_paths, batch_size)\n",
    "validation_gen = image_generator(validation_img_paths, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "125/125 [==============================] - 124s 994ms/step - loss: 58.1819 - dense_2_loss: 14.2789 - dense_3_loss: 14.5552 - dense_4_loss: 14.5749 - dense_5_loss: 14.7728 - dense_2_acc: 0.1135 - dense_3_acc: 0.0963 - dense_4_acc: 0.0953 - dense_5_acc: 0.0830 - val_loss: 58.9570 - val_dense_2_loss: 14.6574 - val_dense_3_loss: 14.5315 - val_dense_4_loss: 14.6070 - val_dense_5_loss: 15.1611 - val_dense_2_acc: 0.0906 - val_dense_3_acc: 0.0984 - val_dense_4_acc: 0.0938 - val_dense_5_acc: 0.0594\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 121s 966ms/step - loss: 57.9848 - dense_2_loss: 14.2323 - dense_3_loss: 14.5264 - dense_4_loss: 14.4902 - dense_5_loss: 14.7360 - dense_2_acc: 0.1170 - dense_3_acc: 0.0988 - dense_4_acc: 0.1010 - dense_5_acc: 0.0858 - val_loss: 59.1584 - val_dense_2_loss: 14.7078 - val_dense_3_loss: 14.8841 - val_dense_4_loss: 14.5567 - val_dense_5_loss: 15.0100 - val_dense_2_acc: 0.0875 - val_dense_3_acc: 0.0766 - val_dense_4_acc: 0.0969 - val_dense_5_acc: 0.0688\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 114s 913ms/step - loss: 57.9204 - dense_2_loss: 14.2282 - dense_3_loss: 14.6594 - dense_4_loss: 14.4982 - dense_5_loss: 14.5345 - dense_2_acc: 0.1173 - dense_3_acc: 0.0905 - dense_4_acc: 0.1005 - dense_5_acc: 0.0983 - val_loss: 59.2844 - val_dense_2_loss: 14.8337 - val_dense_3_loss: 14.5567 - val_dense_4_loss: 14.5818 - val_dense_5_loss: 15.3122 - val_dense_2_acc: 0.0797 - val_dense_3_acc: 0.0969 - val_dense_4_acc: 0.0953 - val_dense_5_acc: 0.0500\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 114s 914ms/step - loss: 57.7793 - dense_2_loss: 14.2041 - dense_3_loss: 14.4015 - dense_4_loss: 14.5708 - dense_5_loss: 14.6030 - dense_2_acc: 0.1188 - dense_3_acc: 0.1065 - dense_4_acc: 0.0960 - dense_5_acc: 0.0940 - val_loss: 59.2088 - val_dense_2_loss: 14.6070 - val_dense_3_loss: 14.7833 - val_dense_4_loss: 14.7833 - val_dense_5_loss: 15.0352 - val_dense_2_acc: 0.0938 - val_dense_3_acc: 0.0828 - val_dense_4_acc: 0.0828 - val_dense_5_acc: 0.0672\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 118s 942ms/step - loss: 57.9325 - dense_2_loss: 14.2927 - dense_3_loss: 14.5546 - dense_4_loss: 14.5103 - dense_5_loss: 14.5748 - dense_2_acc: 0.1133 - dense_3_acc: 0.0970 - dense_4_acc: 0.0998 - dense_5_acc: 0.0958 - val_loss: 59.2088 - val_dense_2_loss: 14.6574 - val_dense_3_loss: 14.9848 - val_dense_4_loss: 14.4559 - val_dense_5_loss: 15.1107 - val_dense_2_acc: 0.0906 - val_dense_3_acc: 0.0703 - val_dense_4_acc: 0.1031 - val_dense_5_acc: 0.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x106c27748>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(training_gen, steps_per_epoch=125, epochs=5, validation_data=validation_gen, \n",
    "                   validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "model.save_weights('first_try_digits.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('digits data/test.png')\n",
    "print(img.shape)\n",
    "img = cv2.resize(img, (320, 120))\n",
    "img = img_to_array(img)\n",
    "\n",
    "plt\n",
    "\n",
    "\n",
    "tab = np.zeros((2, 120, 320, 3))\n",
    "tab[0] = img \n",
    "tab[1] = img \n",
    "\n",
    "model.predict(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2467  105 2997 3271 3356 2227 4933 2308 4600  850 1907 1309 4948 2564\n",
      "  419 3984 2236 1496 2986 1219 1527 1625 2238 4601 2883 3917 4396 4332\n",
      "   39   13 2511  863]\n",
      "[2467  105 2997 3271 3356 2227 4933 2308 4600  850 1907 1309 4948 2564\n",
      "  419 3984 2236 1496 2986 1219 1527 1625 2238 4601 2883 3917 4396 4332\n",
      "   39   13 2511  863]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from random import seed\n",
    "np.random.seed(97)\n",
    "indices = np.random.randint(0, 5000, 32)\n",
    "np.random.seed(97)\n",
    "indices2 = np.random.randint(0, 5000, 32)\n",
    "print(indices)\n",
    "print(indices2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]))\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "bail = get_output('digits data/boards/board_2176.jpg')\n",
    "print(bail)\n",
    "print(bail[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2176\n"
     ]
    }
   ],
   "source": [
    "txt = 'digits data/boards/board_2176.jpg'\n",
    "\n",
    "img_id = txt.split('_')[-1].split('.')[0]\n",
    "print(img_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
